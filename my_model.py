"""
Run this script to recreate the original onnx model.
Example usage:
python my_model_2.py out_model_path.onnx
"""

from onnx import helper, numpy_helper, TensorProto

import onnx
import numpy as np
import sys
import os

DATA_DIR = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'my_model_2')

def clear_field(proto, field):
    proto.ClearField(field)
    return proto

def order_repeated_field(repeated_proto, key_name, order):
    order = list(order)
    repeated_proto.sort(key=lambda x: order.index(getattr(x, key_name)))

def make_node(op_type, inputs, outputs, name=None, doc_string=None, domain=None, **kwargs):
    node = helper.make_node(op_type, inputs, outputs, name, doc_string, domain, **kwargs)
    if doc_string == '':
        node.doc_string = ''
    order_repeated_field(node.attribute, 'name', kwargs.keys())
    return node

def make_graph(*args, doc_string=None, **kwargs):
    graph = helper.make_graph(*args, doc_string=doc_string, **kwargs)
    if doc_string == '':
        graph.doc_string = ''
    return graph

model = helper.make_model(
    opset_imports=[
        clear_field(helper.make_operatorsetid('', 11), 'domain'),
        helper.make_operatorsetid('ai.onnx.ml', 3),
        helper.make_operatorsetid('ai.onnx.training', 1),
        helper.make_operatorsetid('com.ms.internal.nhwc', 18),
        helper.make_operatorsetid('ai.onnx.preview.training', 1),
        helper.make_operatorsetid('com.microsoft', 1),
        helper.make_operatorsetid('com.microsoft.experimental', 1),
        helper.make_operatorsetid('com.microsoft.nchwc', 1),
        helper.make_operatorsetid('org.pytorch.aten', 1),
    ],
    ir_version=8,
    producer_name='onnxruntime.transformers',
    graph=make_graph(
        name='gpt2 beam search',
        inputs=[
            helper.make_tensor_value_info('input_ids', TensorProto.INT32, shape=['batch_size', 'sequence_length']),
            helper.make_tensor_value_info('max_length', TensorProto.INT32, shape=[1]),
            helper.make_tensor_value_info('min_length', TensorProto.INT32, shape=[1]),
            helper.make_tensor_value_info('num_beams', TensorProto.INT32, shape=[1]),
            helper.make_tensor_value_info('num_return_sequences', TensorProto.INT32, shape=[1]),
            helper.make_tensor_value_info('length_penalty', TensorProto.FLOAT, shape=[1]),
            helper.make_tensor_value_info('repetition_penalty', TensorProto.FLOAT, shape=[1]),
        ],
        outputs=[helper.make_tensor_value_info('sequences', TensorProto.INT32, shape=['batch_size', 'num_return_sequences', 'max_length'])],
        initializer=[
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const60_s_d_transformer.wte.weight.npy')).astype('float16').reshape([50110, 256]), name='s_d_transformer.wte.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const61_s_d_transformer.h.0.attn.c_attn.weight.npy')).astype('float16').reshape([256, 768]), name='s_d_transformer.h.0.attn.c_attn.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const62_s_d_transformer.h.0.mlp.c_fc.weight.npy')).astype('float16').reshape([256, 1024]), name='s_d_transformer.h.0.mlp.c_fc.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const63_s_d_transformer.h.0.mlp.c_fc.bias.npy')).astype('float16').reshape([1024]), name='s_d_transformer.h.0.mlp.c_fc.bias'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const64_s_d_transformer.h.0.mlp.c_proj.weight.npy')).astype('float16').reshape([1024, 256]), name='s_d_transformer.h.0.mlp.c_proj.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const65_s_d_transformer.h.1.attn.c_attn.weight.npy')).astype('float16').reshape([256, 768]), name='s_d_transformer.h.1.attn.c_attn.weight'),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const66_s_d_transformer.h.1.mlp.moe_experts.weight1.npy')).astype('float16').reshape([32, 256, 1024]),
                name='s_d_transformer.h.1.mlp.moe_experts.weight1',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const67_s_d_transformer.h.1.mlp.moe_experts.weight2.npy')).astype('float16').reshape([32, 1024, 256]),
                name='s_d_transformer.h.1.mlp.moe_experts.weight2',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const68_s_d_transformer.h.1.mlp.moe_experts.bias1.npy')).astype('float16').reshape([32, 1024]),
                name='s_d_transformer.h.1.mlp.moe_experts.bias1',
            ),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const69_s_d_transformer.h.2.attn.c_attn.weight.npy')).astype('float16').reshape([256, 768]), name='s_d_transformer.h.2.attn.c_attn.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const70_s_d_transformer.h.2.mlp.c_fc.weight.npy')).astype('float16').reshape([256, 1024]), name='s_d_transformer.h.2.mlp.c_fc.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const71_s_d_transformer.h.2.mlp.c_fc.bias.npy')).astype('float16').reshape([1024]), name='s_d_transformer.h.2.mlp.c_fc.bias'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const72_s_d_transformer.h.2.mlp.c_proj.weight.npy')).astype('float16').reshape([1024, 256]), name='s_d_transformer.h.2.mlp.c_proj.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const73_s_d_onnx__MatMul_908.npy')).astype('float16').reshape([256, 50110]), name='s_d_onnx::MatMul_908'),
        ],
        nodes=[
            make_node(
                'BeamSearch',
                inputs=['input_ids', 'max_length', 'min_length', 'num_beams', 'num_return_sequences', 'length_penalty', 'repetition_penalty', '', '', ''],
                outputs=['sequences'],
                name='BeamSearch_gpt2',
                domain='com.microsoft',
                eos_token_id=2,
                pad_token_id=2,
                no_repeat_ngram_size=0,
                early_stopping=0,
                model_type=0,
                init_decoder=make_graph(
                    name='gpt2 init decoder',
                    inputs=[
                        helper.make_tensor_value_info('input_ids', TensorProto.INT32, shape=['batch_size', 1]),
                        helper.make_tensor_value_info('position_ids', TensorProto.INT32, shape=['batch_size', 1]),
                        helper.make_tensor_value_info('attention_mask', TensorProto.INT32, shape=['batch_size', 'total_seq_len']),
                        helper.make_tensor_value_info('past_0', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('past_1', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('past_2', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('past_sequence_length', TensorProto.INT32, shape=[1]),
                        helper.make_tensor_value_info('beam_width', TensorProto.INT32, shape=[1]),
                        helper.make_tensor_value_info('cache_indirection', TensorProto.INT32, shape=['batch_size', 'beam_width', 'max_seq_len']),
                    ],
                    outputs=[
                        helper.make_tensor_value_info('logits', TensorProto.FLOAT, shape=['batch_size', 1, 50110]),
                        helper.make_tensor_value_info('present_0', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('present_1', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('present_2', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                    ],
                    initializer=[
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const0_e_transformer.wpe.weight.npy')).astype('float16').reshape([64, 256]), name='e_transformer.wpe.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const1_e_transformer.h.0.ln_1.weight.npy')).astype('float16').reshape([256]), name='e_transformer.h.0.ln_1.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const2_e_transformer.h.0.ln_1.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.0.ln_1.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const3_e_transformer.h.0.attn.c_attn.bias.npy')).astype('float16').reshape([768]), name='e_transformer.h.0.attn.c_attn.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const4_e_transformer.h.0.attn.c_proj.weight.npy')).astype('float16').reshape([256, 256]), name='e_transformer.h.0.attn.c_proj.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const5_e_transformer.h.0.attn.c_proj.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.0.attn.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const6_e_transformer.h.0.ln_2.weight.npy')).astype('float16').reshape([256]), name='e_transformer.h.0.ln_2.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const7_e_transformer.h.0.ln_2.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.0.ln_2.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const8_e_transformer.h.0.mlp.c_proj.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.0.mlp.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const9_e_transformer.h.1.ln_1.weight.npy')).astype('float16').reshape([256]), name='e_transformer.h.1.ln_1.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const10_e_transformer.h.1.ln_1.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.1.ln_1.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const11_e_transformer.h.1.attn.c_attn.bias.npy')).astype('float16').reshape([768]), name='e_transformer.h.1.attn.c_attn.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const12_e_transformer.h.1.attn.c_proj.weight.npy')).astype('float16').reshape([256, 256]), name='e_transformer.h.1.attn.c_proj.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const13_e_transformer.h.1.attn.c_proj.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.1.attn.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const14_e_transformer.h.1.ln_2.weight.npy')).astype('float16').reshape([256]), name='e_transformer.h.1.ln_2.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const15_e_transformer.h.1.ln_2.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.1.ln_2.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const16_e_onnx__Clip_541.npy')).astype('float16').reshape([32, 1]), name='e_onnx::Clip_541'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const17_e_transformer.h.1.mlp.moe_experts.bias2.npy')).astype('float16').reshape([32, 256]), name='e_transformer.h.1.mlp.moe_experts.bias2'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const18_e_transformer.h.2.ln_1.weight.npy')).astype('float16').reshape([256]), name='e_transformer.h.2.ln_1.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const19_e_transformer.h.2.ln_1.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.2.ln_1.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const20_e_transformer.h.2.attn.c_attn.bias.npy')).astype('float16').reshape([768]), name='e_transformer.h.2.attn.c_attn.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const21_e_transformer.h.2.attn.c_proj.weight.npy')).astype('float16').reshape([256, 256]), name='e_transformer.h.2.attn.c_proj.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const22_e_transformer.h.2.attn.c_proj.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.2.attn.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const23_e_transformer.h.2.ln_2.weight.npy')).astype('float16').reshape([256]), name='e_transformer.h.2.ln_2.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const24_e_transformer.h.2.ln_2.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.2.ln_2.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const25_e_transformer.h.2.mlp.c_proj.bias.npy')).astype('float16').reshape([256]), name='e_transformer.h.2.mlp.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const26_e_transformer.ln_f.weight.npy')).astype('float16').reshape([256]), name='e_transformer.ln_f.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const27_e_transformer.ln_f.bias.npy')).astype('float16').reshape([256]), name='e_transformer.ln_f.bias'),
                        numpy_helper.from_array(np.array([-1], dtype='int64'), name='e_onnx::Concat_851'),
                        numpy_helper.from_array(np.array([256], dtype='int64'), name='e_onnx::Concat_865'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const28_e_onnx__MatMul_887.npy')).astype('float16').reshape([256, 16]), name='e_onnx::MatMul_887'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const29_e_onnx__Cast_539.npy')).astype('float16').reshape([32, 16]), name='e_onnx::Cast_539'),
                        numpy_helper.from_array(np.array(0.00010001659393310547, dtype='float16'), name='e_onnx::Clip_889'),
                        numpy_helper.from_array(np.array(1, dtype='int64'), name='e_onnx::Gather_803'),
                        numpy_helper.from_array(np.array(0, dtype='int64'), name='e_onnx::Gather_800'),
                        numpy_helper.from_array(np.array([0], dtype='int64'), name='e_onnx::Slice_806'),
                        numpy_helper.from_array(np.array([9223372036854775807], dtype='int64'), name='e_onnx::Slice_319'),
                        numpy_helper.from_array(np.array(2, dtype='int64'), name='e_onnx::Gather_526'),
                        numpy_helper.from_array(np.array([32, 16], dtype='int64'), name='e_onnx::Expand_546'),
                    ],
                    doc_string='',
                    value_info=[
                        helper.make_tensor_value_info('e_onnx::Expand_545', TensorProto.FLOAT16, shape=[32, 1]),
                        helper.make_tensor_value_info('e_onnx::Div_547', TensorProto.FLOAT16, shape=[32, 16]),
                        helper.make_tensor_value_info('e_onnx::Transpose_548', TensorProto.FLOAT16, shape=[32, 16]),
                        helper.make_tensor_value_info('e_onnx::MatMul_550', TensorProto.FLOAT16, shape=[16, 32]),
                        helper.make_tensor_value_info('e_EmbedLayerNormalization_0_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_EmbedLayerNormalization_0_dummy_mask_index', TensorProto.INT32, shape=['batch_size']),
                        helper.make_tensor_value_info('e_EmbedLayerNormalization_0_embedding_sum', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_graph_input_cast_3', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'past_seq_len', 32]),
                        helper.make_tensor_value_info('e_graph_input_cast_4', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'past_seq_len', 32]),
                        helper.make_tensor_value_info('e_graph_input_cast_5', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'past_seq_len', 32]),
                        helper.make_tensor_value_info('e_GptAttention_0_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_graph_output_cast_1', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('e_GptAttention_0_matmul_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_FullyConnect_MatMul_0_input', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('e_input.19', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_FullyConnect_MatMul_0_output', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('e_onnx::Shape_309', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('e_onnx::Gather_313', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_315', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_330', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_312', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_329', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Reshape_332', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('e_onnx::Squeeze_320', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_321', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_324', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Reshape_325', TensorProto.INT64, shape=[2]),
                        helper.make_tensor_value_info('e_onnx::Gemm_326', TensorProto.FLOAT16, shape=['batch_size', 1024]),
                        helper.make_tensor_value_info('e_onnx::Reshape_327', TensorProto.FLOAT16, shape=['batch_size', 256]),
                        helper.make_tensor_value_info('e_input.23', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_onnx::Shape_345', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('e_input.27', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_GptAttention_1_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_graph_output_cast_2', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('e_GptAttention_1_matmul_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_onnx::Shape_518', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('e_input.39', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_onnx::Gather_525', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_527', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_579', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Reshape_531', TensorProto.INT64, shape=[2]),
                        helper.make_tensor_value_info('e_onnx::MatMul_532', TensorProto.FLOAT16, shape=['batch_size', 256]),
                        helper.make_tensor_value_info('e_input.43', TensorProto.FLOAT16, shape=['batch_size', 16]),
                        helper.make_tensor_value_info('e_onnx::Softmax_551', TensorProto.FLOAT16, shape=['batch_size', 32]),
                        helper.make_tensor_value_info('e_onnx::Add_581', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_onnx::Shape_593', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('e_input.51', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_GptAttention_2_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_graph_output_cast_3', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('e_GptAttention_2_matmul_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_FullyConnect_MatMul_1_input', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('e_input.63', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_FullyConnect_MatMul_1_output', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('e_onnx::Shape_798', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('e_onnx::Gather_802', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_804', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_819', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_801', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_818', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Reshape_821', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('e_onnx::Squeeze_809', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Unsqueeze_810', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('e_onnx::Concat_813', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('e_onnx::Reshape_814', TensorProto.INT64, shape=[2]),
                        helper.make_tensor_value_info('e_onnx::Gemm_815', TensorProto.FLOAT16, shape=['batch_size', 1024]),
                        helper.make_tensor_value_info('e_onnx::Reshape_816', TensorProto.FLOAT16, shape=['batch_size', 256]),
                        helper.make_tensor_value_info('e_input.67', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_onnx::Reshape_834', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('e_graph_output_cast_0', TensorProto.FLOAT16, shape=['batch_size', 1, 50110]),
                        helper.make_tensor_value_info('logits', TensorProto.FLOAT, shape=['batch_size', 1, 50110]),
                        helper.make_tensor_value_info('present_0', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('present_1', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('present_2', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('s_d_transformer.wte.weight', TensorProto.FLOAT16, shape=[50110, 256]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.attn.c_attn.weight', TensorProto.FLOAT16, shape=[256, 768]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.mlp.c_fc.weight', TensorProto.FLOAT16, shape=[256, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.mlp.c_fc.bias', TensorProto.FLOAT16, shape=[1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.mlp.c_proj.weight', TensorProto.FLOAT16, shape=[1024, 256]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.attn.c_attn.weight', TensorProto.FLOAT16, shape=[256, 768]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.mlp.moe_experts.weight1', TensorProto.FLOAT16, shape=[32, 256, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.mlp.moe_experts.weight2', TensorProto.FLOAT16, shape=[32, 1024, 256]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.mlp.moe_experts.bias1', TensorProto.FLOAT16, shape=[32, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.attn.c_attn.weight', TensorProto.FLOAT16, shape=[256, 768]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.mlp.c_fc.weight', TensorProto.FLOAT16, shape=[256, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.mlp.c_fc.bias', TensorProto.FLOAT16, shape=[1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.mlp.c_proj.weight', TensorProto.FLOAT16, shape=[1024, 256]),
                        helper.make_tensor_value_info('s_d_onnx::MatMul_908', TensorProto.FLOAT16, shape=[256, 50110]),
                    ],
                    nodes=[
                        make_node('Clip', inputs=['e_onnx::Clip_541', 'e_onnx::Clip_889', ''], outputs=['e_onnx::Expand_545'], name='Clip_455'),
                        make_node('Expand', inputs=['e_onnx::Expand_545', 'e_onnx::Expand_546'], outputs=['e_onnx::Div_547'], name='Expand_457'),
                        make_node('Div', inputs=['e_onnx::Cast_539', 'e_onnx::Div_547'], outputs=['e_onnx::Transpose_548'], name='Div_458'),
                        make_node('Transpose', inputs=['e_onnx::Transpose_548'], outputs=['e_onnx::MatMul_550'], name='Transpose_460', perm=[1, 0]),
                        make_node(
                            'EmbedLayerNormalization',
                            inputs=['input_ids', '', 's_d_transformer.wte.weight', 'e_transformer.wpe.weight', '', 'e_transformer.h.0.ln_1.weight', 'e_transformer.h.0.ln_1.bias', '', 'position_ids'],
                            outputs=['e_EmbedLayerNormalization_0_output', 'e_EmbedLayerNormalization_0_dummy_mask_index', 'e_EmbedLayerNormalization_0_embedding_sum'],
                            name='EmbedLayerNormalization_0',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('Cast', inputs=['past_0'], outputs=['e_graph_input_cast_3'], name='graph_input_cast3', to=TensorProto.FLOAT16),
                        make_node('Cast', inputs=['past_1'], outputs=['e_graph_input_cast_4'], name='graph_input_cast4', to=TensorProto.FLOAT16),
                        make_node('Cast', inputs=['past_2'], outputs=['e_graph_input_cast_5'], name='graph_input_cast5', to=TensorProto.FLOAT16),
                        make_node(
                            'Attention',
                            inputs=['e_EmbedLayerNormalization_0_output', 's_d_transformer.h.0.attn.c_attn.weight', 'e_transformer.h.0.attn.c_attn.bias', 'attention_mask', 'e_graph_input_cast_3', '', 'past_sequence_length'],
                            outputs=['e_GptAttention_0_output', 'e_graph_output_cast_1'],
                            name='GptAttention_0',
                            domain='com.microsoft',
                            mask_filter_value=-3.4028234663852886e+38,
                            num_heads=8,
                            past_present_share_buffer=1,
                            unidirectional=1,
                        ),
                        make_node('MatMul', inputs=['e_GptAttention_0_output', 'e_transformer.h.0.attn.c_proj.weight'], outputs=['e_GptAttention_0_matmul_output'], name='GptAttention_0_matmul'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['e_EmbedLayerNormalization_0_embedding_sum', 'e_GptAttention_0_matmul_output', 'e_transformer.h.0.ln_2.weight', 'e_transformer.h.0.ln_2.bias', 'e_transformer.h.0.attn.c_proj.bias'],
                            outputs=['e_FullyConnect_MatMul_0_input', '', '', 'e_input.19'],
                            name='SkipLayerNorm_AddBias_0',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('MatMul', inputs=['e_FullyConnect_MatMul_0_input', 's_d_transformer.h.0.mlp.c_fc.weight'], outputs=['e_FullyConnect_MatMul_0_output'], name='FullyConnect_MatMul_0'),
                        make_node('BiasGelu', inputs=['e_FullyConnect_MatMul_0_output', 's_d_transformer.h.0.mlp.c_fc.bias'], outputs=['e_onnx::Shape_309'], name='Gelu_AddBias_0', domain='com.microsoft'),
                        make_node('Shape', inputs=['e_onnx::Shape_309'], outputs=['e_onnx::Gather_313'], name='Shape_265'),
                        make_node('Gather', inputs=['e_onnx::Gather_313', 'e_onnx::Gather_803'], outputs=['e_onnx::Unsqueeze_315'], name='Gather_267', axis=0),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_315'], outputs=['e_onnx::Concat_330'], name='Unsqueeze_279', axes=[0]),
                        make_node('Gather', inputs=['e_onnx::Gather_313', 'e_onnx::Gather_800'], outputs=['e_onnx::Unsqueeze_312'], name='Gather_264', axis=0),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_312'], outputs=['e_onnx::Concat_329'], name='Unsqueeze_278', axes=[0]),
                        make_node('Concat', inputs=['e_onnx::Concat_329', 'e_onnx::Concat_330', 'e_onnx::Concat_865'], outputs=['e_onnx::Reshape_332'], name='Concat_280', axis=0),
                        make_node('Slice', inputs=['e_onnx::Gather_313', 'e_onnx::Concat_851', 'e_onnx::Slice_319', 'e_onnx::Slice_806'], outputs=['e_onnx::Squeeze_320'], name='Slice_272'),
                        make_node('Squeeze', inputs=['e_onnx::Squeeze_320'], outputs=['e_onnx::Unsqueeze_321'], name='Squeeze_273', axes=[0]),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_321'], outputs=['e_onnx::Concat_324'], name='Unsqueeze_274', axes=[0]),
                        make_node('Concat', inputs=['e_onnx::Concat_851', 'e_onnx::Concat_324'], outputs=['e_onnx::Reshape_325'], name='Concat_275', axis=0),
                        make_node('Reshape', inputs=['e_onnx::Shape_309', 'e_onnx::Reshape_325'], outputs=['e_onnx::Gemm_326'], name='Reshape_276'),
                        make_node(
                            'Gemm',
                            inputs=['e_onnx::Gemm_326', 's_d_transformer.h.0.mlp.c_proj.weight', 'e_transformer.h.0.mlp.c_proj.bias'],
                            outputs=['e_onnx::Reshape_327'],
                            name='Gemm_277',
                            transB=0,
                            transA=0,
                            alpha=1.0,
                            beta=1.0,
                        ),
                        make_node('Reshape', inputs=['e_onnx::Reshape_327', 'e_onnx::Reshape_332'], outputs=['e_input.23'], name='Reshape_281'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['e_input.19', 'e_input.23', 'e_transformer.h.1.ln_1.weight', 'e_transformer.h.1.ln_1.bias'],
                            outputs=['e_onnx::Shape_345', '', '', 'e_input.27'],
                            name='SkipLayerNorm_1',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node(
                            'Attention',
                            inputs=['e_onnx::Shape_345', 's_d_transformer.h.1.attn.c_attn.weight', 'e_transformer.h.1.attn.c_attn.bias', 'attention_mask', 'e_graph_input_cast_4', '', 'past_sequence_length'],
                            outputs=['e_GptAttention_1_output', 'e_graph_output_cast_2'],
                            name='GptAttention_1',
                            domain='com.microsoft',
                            mask_filter_value=-3.4028234663852886e+38,
                            num_heads=8,
                            past_present_share_buffer=1,
                            unidirectional=1,
                        ),
                        make_node('MatMul', inputs=['e_GptAttention_1_output', 'e_transformer.h.1.attn.c_proj.weight'], outputs=['e_GptAttention_1_matmul_output'], name='GptAttention_1_matmul'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['e_input.27', 'e_GptAttention_1_matmul_output', 'e_transformer.h.1.ln_2.weight', 'e_transformer.h.1.ln_2.bias', 'e_transformer.h.1.attn.c_proj.bias'],
                            outputs=['e_onnx::Shape_518', '', '', 'e_input.39'],
                            name='SkipLayerNorm_AddBias_1',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('Shape', inputs=['e_onnx::Shape_518'], outputs=['e_onnx::Gather_525'], name='Shape_442'),
                        make_node('Gather', inputs=['e_onnx::Gather_525', 'e_onnx::Gather_526'], outputs=['e_onnx::Unsqueeze_527'], name='Gather_444', axis=0),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_527'], outputs=['e_onnx::Concat_579'], name='Unsqueeze_489', axes=[0]),
                        make_node('Concat', inputs=['e_onnx::Concat_851', 'e_onnx::Concat_579'], outputs=['e_onnx::Reshape_531'], name='Concat_446', axis=0),
                        make_node('Reshape', inputs=['e_onnx::Shape_518', 'e_onnx::Reshape_531'], outputs=['e_onnx::MatMul_532'], name='Reshape_447'),
                        make_node('MatMul', inputs=['e_onnx::MatMul_532', 'e_onnx::MatMul_887'], outputs=['e_input.43'], name='MatMul_448'),
                        make_node('MatMul', inputs=['e_input.43', 'e_onnx::MatMul_550'], outputs=['e_onnx::Softmax_551'], name='MatMul_461'),
                        make_node(
                            'MoEBlock',
                            inputs=[
                                'e_onnx::Shape_518',
                                '',
                                's_d_transformer.h.1.mlp.moe_experts.weight1',
                                's_d_transformer.h.1.mlp.moe_experts.weight2',
                                's_d_transformer.h.1.mlp.moe_experts.bias1',
                                'e_transformer.h.1.mlp.moe_experts.bias2',
                                'e_onnx::Softmax_551',
                            ],
                            outputs=['e_onnx::Add_581'],
                            name='MoEBlock_0',
                            domain='com.microsoft',
                        ),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['e_input.39', 'e_onnx::Add_581', 'e_transformer.h.2.ln_1.weight', 'e_transformer.h.2.ln_1.bias'],
                            outputs=['e_onnx::Shape_593', '', '', 'e_input.51'],
                            name='SkipLayerNorm_3',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node(
                            'Attention',
                            inputs=['e_onnx::Shape_593', 's_d_transformer.h.2.attn.c_attn.weight', 'e_transformer.h.2.attn.c_attn.bias', 'attention_mask', 'e_graph_input_cast_5', '', 'past_sequence_length'],
                            outputs=['e_GptAttention_2_output', 'e_graph_output_cast_3'],
                            name='GptAttention_2',
                            domain='com.microsoft',
                            mask_filter_value=-3.4028234663852886e+38,
                            num_heads=8,
                            past_present_share_buffer=1,
                            unidirectional=1,
                        ),
                        make_node('MatMul', inputs=['e_GptAttention_2_output', 'e_transformer.h.2.attn.c_proj.weight'], outputs=['e_GptAttention_2_matmul_output'], name='GptAttention_2_matmul'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['e_input.51', 'e_GptAttention_2_matmul_output', 'e_transformer.h.2.ln_2.weight', 'e_transformer.h.2.ln_2.bias', 'e_transformer.h.2.attn.c_proj.bias'],
                            outputs=['e_FullyConnect_MatMul_1_input', '', '', 'e_input.63'],
                            name='SkipLayerNorm_AddBias_2',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('MatMul', inputs=['e_FullyConnect_MatMul_1_input', 's_d_transformer.h.2.mlp.c_fc.weight'], outputs=['e_FullyConnect_MatMul_1_output'], name='FullyConnect_MatMul_1'),
                        make_node('BiasGelu', inputs=['e_FullyConnect_MatMul_1_output', 's_d_transformer.h.2.mlp.c_fc.bias'], outputs=['e_onnx::Shape_798'], name='Gelu_AddBias_1', domain='com.microsoft'),
                        make_node('Shape', inputs=['e_onnx::Shape_798'], outputs=['e_onnx::Gather_802'], name='Shape_677'),
                        make_node('Gather', inputs=['e_onnx::Gather_802', 'e_onnx::Gather_803'], outputs=['e_onnx::Unsqueeze_804'], name='Gather_679', axis=0),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_804'], outputs=['e_onnx::Concat_819'], name='Unsqueeze_691', axes=[0]),
                        make_node('Gather', inputs=['e_onnx::Gather_802', 'e_onnx::Gather_800'], outputs=['e_onnx::Unsqueeze_801'], name='Gather_676', axis=0),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_801'], outputs=['e_onnx::Concat_818'], name='Unsqueeze_690', axes=[0]),
                        make_node('Concat', inputs=['e_onnx::Concat_818', 'e_onnx::Concat_819', 'e_onnx::Concat_865'], outputs=['e_onnx::Reshape_821'], name='Concat_692', axis=0),
                        make_node('Slice', inputs=['e_onnx::Gather_802', 'e_onnx::Concat_851', 'e_onnx::Slice_319', 'e_onnx::Slice_806'], outputs=['e_onnx::Squeeze_809'], name='Slice_684'),
                        make_node('Squeeze', inputs=['e_onnx::Squeeze_809'], outputs=['e_onnx::Unsqueeze_810'], name='Squeeze_685', axes=[0]),
                        make_node('Unsqueeze', inputs=['e_onnx::Unsqueeze_810'], outputs=['e_onnx::Concat_813'], name='Unsqueeze_686', axes=[0]),
                        make_node('Concat', inputs=['e_onnx::Concat_851', 'e_onnx::Concat_813'], outputs=['e_onnx::Reshape_814'], name='Concat_687', axis=0),
                        make_node('Reshape', inputs=['e_onnx::Shape_798', 'e_onnx::Reshape_814'], outputs=['e_onnx::Gemm_815'], name='Reshape_688'),
                        make_node(
                            'Gemm',
                            inputs=['e_onnx::Gemm_815', 's_d_transformer.h.2.mlp.c_proj.weight', 'e_transformer.h.2.mlp.c_proj.bias'],
                            outputs=['e_onnx::Reshape_816'],
                            name='Gemm_689',
                            transB=0,
                            transA=0,
                            alpha=1.0,
                            beta=1.0,
                        ),
                        make_node('Reshape', inputs=['e_onnx::Reshape_816', 'e_onnx::Reshape_821'], outputs=['e_input.67'], name='Reshape_693'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['e_input.63', 'e_input.67', 'e_transformer.ln_f.weight', 'e_transformer.ln_f.bias'],
                            outputs=['e_onnx::Reshape_834'],
                            name='SkipLayerNorm_5',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('MatMul', inputs=['e_onnx::Reshape_834', 's_d_onnx::MatMul_908'], outputs=['e_graph_output_cast_0'], name='MatMul_711'),
                        make_node('Cast', inputs=['e_graph_output_cast_0'], outputs=['logits'], name='graph_output_cast0', to=TensorProto.FLOAT),
                        make_node('Cast', inputs=['e_graph_output_cast_1'], outputs=['present_0'], name='graph_output_cast1', to=TensorProto.FLOAT),
                        make_node('Cast', inputs=['e_graph_output_cast_2'], outputs=['present_1'], name='graph_output_cast2', to=TensorProto.FLOAT),
                        make_node('Cast', inputs=['e_graph_output_cast_3'], outputs=['present_2'], name='graph_output_cast3', to=TensorProto.FLOAT),
                    ],
                ),
                decoder=make_graph(
                    name='gpt2 decoder',
                    inputs=[
                        helper.make_tensor_value_info('input_ids', TensorProto.INT32, shape=['batch_size', 1]),
                        helper.make_tensor_value_info('position_ids', TensorProto.INT32, shape=['batch_size', 1]),
                        helper.make_tensor_value_info('attention_mask', TensorProto.INT32, shape=['batch_size', 'total_seq_len']),
                        helper.make_tensor_value_info('past_0', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('past_1', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('past_2', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('past_sequence_length', TensorProto.INT32, shape=[1]),
                        helper.make_tensor_value_info('beam_width', TensorProto.INT32, shape=[1]),
                        helper.make_tensor_value_info('cache_indirection', TensorProto.INT32, shape=['batch_size', 'beam_width', 'max_seq_len']),
                    ],
                    outputs=[
                        helper.make_tensor_value_info('logits', TensorProto.FLOAT, shape=['batch_size', 1, 50110]),
                        helper.make_tensor_value_info('present_0', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('present_1', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                        helper.make_tensor_value_info('present_2', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'max_seq_len', 32]),
                    ],
                    initializer=[
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const30_d_transformer.wpe.weight.npy')).astype('float16').reshape([64, 256]), name='d_transformer.wpe.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const31_d_transformer.h.0.ln_1.weight.npy')).astype('float16').reshape([256]), name='d_transformer.h.0.ln_1.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const32_d_transformer.h.0.ln_1.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.0.ln_1.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const33_d_transformer.h.0.attn.c_attn.bias.npy')).astype('float16').reshape([768]), name='d_transformer.h.0.attn.c_attn.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const34_d_transformer.h.0.attn.c_proj.weight.npy')).astype('float16').reshape([256, 256]), name='d_transformer.h.0.attn.c_proj.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const35_d_transformer.h.0.attn.c_proj.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.0.attn.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const36_d_transformer.h.0.ln_2.weight.npy')).astype('float16').reshape([256]), name='d_transformer.h.0.ln_2.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const37_d_transformer.h.0.ln_2.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.0.ln_2.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const38_d_transformer.h.0.mlp.c_proj.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.0.mlp.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const39_d_transformer.h.1.ln_1.weight.npy')).astype('float16').reshape([256]), name='d_transformer.h.1.ln_1.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const40_d_transformer.h.1.ln_1.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.1.ln_1.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const41_d_transformer.h.1.attn.c_attn.bias.npy')).astype('float16').reshape([768]), name='d_transformer.h.1.attn.c_attn.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const42_d_transformer.h.1.attn.c_proj.weight.npy')).astype('float16').reshape([256, 256]), name='d_transformer.h.1.attn.c_proj.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const43_d_transformer.h.1.attn.c_proj.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.1.attn.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const44_d_transformer.h.1.ln_2.weight.npy')).astype('float16').reshape([256]), name='d_transformer.h.1.ln_2.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const45_d_transformer.h.1.ln_2.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.1.ln_2.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const46_d_onnx__Clip_541.npy')).astype('float16').reshape([32, 1]), name='d_onnx::Clip_541'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const47_d_transformer.h.1.mlp.moe_experts.bias2.npy')).astype('float16').reshape([32, 256]), name='d_transformer.h.1.mlp.moe_experts.bias2'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const48_d_transformer.h.2.ln_1.weight.npy')).astype('float16').reshape([256]), name='d_transformer.h.2.ln_1.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const49_d_transformer.h.2.ln_1.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.2.ln_1.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const50_d_transformer.h.2.attn.c_attn.bias.npy')).astype('float16').reshape([768]), name='d_transformer.h.2.attn.c_attn.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const51_d_transformer.h.2.attn.c_proj.weight.npy')).astype('float16').reshape([256, 256]), name='d_transformer.h.2.attn.c_proj.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const52_d_transformer.h.2.attn.c_proj.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.2.attn.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const53_d_transformer.h.2.ln_2.weight.npy')).astype('float16').reshape([256]), name='d_transformer.h.2.ln_2.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const54_d_transformer.h.2.ln_2.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.2.ln_2.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const55_d_transformer.h.2.mlp.c_proj.bias.npy')).astype('float16').reshape([256]), name='d_transformer.h.2.mlp.c_proj.bias'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const56_d_transformer.ln_f.weight.npy')).astype('float16').reshape([256]), name='d_transformer.ln_f.weight'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const57_d_transformer.ln_f.bias.npy')).astype('float16').reshape([256]), name='d_transformer.ln_f.bias'),
                        numpy_helper.from_array(np.array([-1], dtype='int64'), name='d_onnx::Concat_851'),
                        numpy_helper.from_array(np.array([256], dtype='int64'), name='d_onnx::Concat_865'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const58_d_onnx__MatMul_887.npy')).astype('float16').reshape([256, 16]), name='d_onnx::MatMul_887'),
                        numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const59_d_onnx__Cast_539.npy')).astype('float16').reshape([32, 16]), name='d_onnx::Cast_539'),
                        numpy_helper.from_array(np.array(0.00010001659393310547, dtype='float16'), name='d_onnx::Clip_889'),
                        numpy_helper.from_array(np.array(1, dtype='int64'), name='d_onnx::Gather_803'),
                        numpy_helper.from_array(np.array(0, dtype='int64'), name='d_onnx::Gather_800'),
                        numpy_helper.from_array(np.array([0], dtype='int64'), name='d_onnx::Slice_806'),
                        numpy_helper.from_array(np.array([9223372036854775807], dtype='int64'), name='d_onnx::Slice_319'),
                        numpy_helper.from_array(np.array(2, dtype='int64'), name='d_onnx::Gather_526'),
                        numpy_helper.from_array(np.array([32, 16], dtype='int64'), name='d_onnx::Expand_546'),
                    ],
                    doc_string='',
                    value_info=[
                        helper.make_tensor_value_info('d_onnx::Expand_545', TensorProto.FLOAT16, shape=[32, 1]),
                        helper.make_tensor_value_info('d_onnx::Div_547', TensorProto.FLOAT16, shape=[32, 16]),
                        helper.make_tensor_value_info('d_onnx::Transpose_548', TensorProto.FLOAT16, shape=[32, 16]),
                        helper.make_tensor_value_info('d_onnx::MatMul_550', TensorProto.FLOAT16, shape=[16, 32]),
                        helper.make_tensor_value_info('d_EmbedLayerNormalization_0_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_EmbedLayerNormalization_0_dummy_mask_index', TensorProto.INT32, shape=['batch_size']),
                        helper.make_tensor_value_info('d_EmbedLayerNormalization_0_embedding_sum', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_graph_input_cast_3', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'past_seq_len', 32]),
                        helper.make_tensor_value_info('d_graph_input_cast_4', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'past_seq_len', 32]),
                        helper.make_tensor_value_info('d_graph_input_cast_5', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'past_seq_len', 32]),
                        helper.make_tensor_value_info('d_GptAttention_0_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_graph_output_cast_1', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('d_GptAttention_0_matmul_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_FullyConnect_MatMul_0_input', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('d_input.19', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_FullyConnect_MatMul_0_output', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('d_onnx::Shape_309', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('d_onnx::Gather_313', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_315', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_330', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_312', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_329', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Reshape_332', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('d_onnx::Squeeze_320', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_321', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_324', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Reshape_325', TensorProto.INT64, shape=[2]),
                        helper.make_tensor_value_info('d_onnx::Gemm_326', TensorProto.FLOAT16, shape=['batch_size', 1024]),
                        helper.make_tensor_value_info('d_onnx::Reshape_327', TensorProto.FLOAT16, shape=['batch_size', 256]),
                        helper.make_tensor_value_info('d_input.23', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_onnx::Shape_345', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('d_input.27', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_GptAttention_1_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_graph_output_cast_2', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('d_GptAttention_1_matmul_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_onnx::Shape_518', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('d_input.39', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_onnx::Gather_525', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_527', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_579', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Reshape_531', TensorProto.INT64, shape=[2]),
                        helper.make_tensor_value_info('d_onnx::MatMul_532', TensorProto.FLOAT16, shape=['batch_size', 256]),
                        helper.make_tensor_value_info('d_input.43', TensorProto.FLOAT16, shape=['batch_size', 16]),
                        helper.make_tensor_value_info('d_onnx::Softmax_551', TensorProto.FLOAT16, shape=['batch_size', 32]),
                        helper.make_tensor_value_info('d_onnx::Add_581', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_onnx::Shape_593', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('d_input.51', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_GptAttention_2_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_graph_output_cast_3', TensorProto.FLOAT16, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('d_GptAttention_2_matmul_output', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_FullyConnect_MatMul_1_input', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('', TensorProto.UNDEFINED, shape=None),
                        helper.make_tensor_value_info('d_input.63', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_FullyConnect_MatMul_1_output', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('d_onnx::Shape_798', TensorProto.FLOAT16, shape=['batch_size', 1, 1024]),
                        helper.make_tensor_value_info('d_onnx::Gather_802', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_804', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_819', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_801', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_818', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Reshape_821', TensorProto.INT64, shape=[3]),
                        helper.make_tensor_value_info('d_onnx::Squeeze_809', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Unsqueeze_810', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('d_onnx::Concat_813', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('d_onnx::Reshape_814', TensorProto.INT64, shape=[2]),
                        helper.make_tensor_value_info('d_onnx::Gemm_815', TensorProto.FLOAT16, shape=['batch_size', 1024]),
                        helper.make_tensor_value_info('d_onnx::Reshape_816', TensorProto.FLOAT16, shape=['batch_size', 256]),
                        helper.make_tensor_value_info('d_input.67', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_onnx::Reshape_834', TensorProto.FLOAT16, shape=['batch_size', 1, 256]),
                        helper.make_tensor_value_info('d_graph_output_cast_0', TensorProto.FLOAT16, shape=['batch_size', 1, 50110]),
                        helper.make_tensor_value_info('logits', TensorProto.FLOAT, shape=['batch_size', 1, 50110]),
                        helper.make_tensor_value_info('present_0', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('present_1', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('present_2', TensorProto.FLOAT, shape=[2, 'batch_size', 8, 'total_seq_len', 32]),
                        helper.make_tensor_value_info('s_d_transformer.wte.weight', TensorProto.FLOAT16, shape=[50110, 256]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.attn.c_attn.weight', TensorProto.FLOAT16, shape=[256, 768]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.mlp.c_fc.weight', TensorProto.FLOAT16, shape=[256, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.mlp.c_fc.bias', TensorProto.FLOAT16, shape=[1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.0.mlp.c_proj.weight', TensorProto.FLOAT16, shape=[1024, 256]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.attn.c_attn.weight', TensorProto.FLOAT16, shape=[256, 768]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.mlp.moe_experts.weight1', TensorProto.FLOAT16, shape=[32, 256, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.mlp.moe_experts.weight2', TensorProto.FLOAT16, shape=[32, 1024, 256]),
                        helper.make_tensor_value_info('s_d_transformer.h.1.mlp.moe_experts.bias1', TensorProto.FLOAT16, shape=[32, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.attn.c_attn.weight', TensorProto.FLOAT16, shape=[256, 768]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.mlp.c_fc.weight', TensorProto.FLOAT16, shape=[256, 1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.mlp.c_fc.bias', TensorProto.FLOAT16, shape=[1024]),
                        helper.make_tensor_value_info('s_d_transformer.h.2.mlp.c_proj.weight', TensorProto.FLOAT16, shape=[1024, 256]),
                        helper.make_tensor_value_info('s_d_onnx::MatMul_908', TensorProto.FLOAT16, shape=[256, 50110]),
                    ],
                    nodes=[
                        make_node('Clip', inputs=['d_onnx::Clip_541', 'd_onnx::Clip_889', ''], outputs=['d_onnx::Expand_545'], name='Clip_455'),
                        make_node('Expand', inputs=['d_onnx::Expand_545', 'd_onnx::Expand_546'], outputs=['d_onnx::Div_547'], name='Expand_457'),
                        make_node('Div', inputs=['d_onnx::Cast_539', 'd_onnx::Div_547'], outputs=['d_onnx::Transpose_548'], name='Div_458'),
                        make_node('Transpose', inputs=['d_onnx::Transpose_548'], outputs=['d_onnx::MatMul_550'], name='Transpose_460', perm=[1, 0]),
                        make_node(
                            'EmbedLayerNormalization',
                            inputs=['input_ids', '', 's_d_transformer.wte.weight', 'd_transformer.wpe.weight', '', 'd_transformer.h.0.ln_1.weight', 'd_transformer.h.0.ln_1.bias', '', 'position_ids'],
                            outputs=['d_EmbedLayerNormalization_0_output', 'd_EmbedLayerNormalization_0_dummy_mask_index', 'd_EmbedLayerNormalization_0_embedding_sum'],
                            name='EmbedLayerNormalization_0',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('Cast', inputs=['past_0'], outputs=['d_graph_input_cast_3'], name='graph_input_cast3', to=TensorProto.FLOAT16),
                        make_node('Cast', inputs=['past_1'], outputs=['d_graph_input_cast_4'], name='graph_input_cast4', to=TensorProto.FLOAT16),
                        make_node('Cast', inputs=['past_2'], outputs=['d_graph_input_cast_5'], name='graph_input_cast5', to=TensorProto.FLOAT16),
                        make_node(
                            'DecoderMaskedSelfAttention',
                            inputs=[
                                'd_EmbedLayerNormalization_0_output',
                                's_d_transformer.h.0.attn.c_attn.weight',
                                'd_transformer.h.0.attn.c_attn.bias',
                                'attention_mask',
                                'd_graph_input_cast_3',
                                '',
                                'past_sequence_length',
                                'beam_width',
                                'cache_indirection',
                            ],
                            outputs=['d_GptAttention_0_output', 'd_graph_output_cast_1'],
                            name='GptAttention_0',
                            domain='com.microsoft',
                            mask_filter_value=-3.4028234663852886e+38,
                            num_heads=8,
                            past_present_share_buffer=1,
                        ),
                        make_node('MatMul', inputs=['d_GptAttention_0_output', 'd_transformer.h.0.attn.c_proj.weight'], outputs=['d_GptAttention_0_matmul_output'], name='GptAttention_0_matmul'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['d_EmbedLayerNormalization_0_embedding_sum', 'd_GptAttention_0_matmul_output', 'd_transformer.h.0.ln_2.weight', 'd_transformer.h.0.ln_2.bias', 'd_transformer.h.0.attn.c_proj.bias'],
                            outputs=['d_FullyConnect_MatMul_0_input', '', '', 'd_input.19'],
                            name='SkipLayerNorm_AddBias_0',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('MatMul', inputs=['d_FullyConnect_MatMul_0_input', 's_d_transformer.h.0.mlp.c_fc.weight'], outputs=['d_FullyConnect_MatMul_0_output'], name='FullyConnect_MatMul_0'),
                        make_node('BiasGelu', inputs=['d_FullyConnect_MatMul_0_output', 's_d_transformer.h.0.mlp.c_fc.bias'], outputs=['d_onnx::Shape_309'], name='Gelu_AddBias_0', domain='com.microsoft'),
                        make_node('Shape', inputs=['d_onnx::Shape_309'], outputs=['d_onnx::Gather_313'], name='Shape_265'),
                        make_node('Gather', inputs=['d_onnx::Gather_313', 'd_onnx::Gather_803'], outputs=['d_onnx::Unsqueeze_315'], name='Gather_267', axis=0),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_315'], outputs=['d_onnx::Concat_330'], name='Unsqueeze_279', axes=[0]),
                        make_node('Gather', inputs=['d_onnx::Gather_313', 'd_onnx::Gather_800'], outputs=['d_onnx::Unsqueeze_312'], name='Gather_264', axis=0),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_312'], outputs=['d_onnx::Concat_329'], name='Unsqueeze_278', axes=[0]),
                        make_node('Concat', inputs=['d_onnx::Concat_329', 'd_onnx::Concat_330', 'd_onnx::Concat_865'], outputs=['d_onnx::Reshape_332'], name='Concat_280', axis=0),
                        make_node('Slice', inputs=['d_onnx::Gather_313', 'd_onnx::Concat_851', 'd_onnx::Slice_319', 'd_onnx::Slice_806'], outputs=['d_onnx::Squeeze_320'], name='Slice_272'),
                        make_node('Squeeze', inputs=['d_onnx::Squeeze_320'], outputs=['d_onnx::Unsqueeze_321'], name='Squeeze_273', axes=[0]),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_321'], outputs=['d_onnx::Concat_324'], name='Unsqueeze_274', axes=[0]),
                        make_node('Concat', inputs=['d_onnx::Concat_851', 'd_onnx::Concat_324'], outputs=['d_onnx::Reshape_325'], name='Concat_275', axis=0),
                        make_node('Reshape', inputs=['d_onnx::Shape_309', 'd_onnx::Reshape_325'], outputs=['d_onnx::Gemm_326'], name='Reshape_276'),
                        make_node(
                            'Gemm',
                            inputs=['d_onnx::Gemm_326', 's_d_transformer.h.0.mlp.c_proj.weight', 'd_transformer.h.0.mlp.c_proj.bias'],
                            outputs=['d_onnx::Reshape_327'],
                            name='Gemm_277',
                            transB=0,
                            transA=0,
                            alpha=1.0,
                            beta=1.0,
                        ),
                        make_node('Reshape', inputs=['d_onnx::Reshape_327', 'd_onnx::Reshape_332'], outputs=['d_input.23'], name='Reshape_281'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['d_input.19', 'd_input.23', 'd_transformer.h.1.ln_1.weight', 'd_transformer.h.1.ln_1.bias'],
                            outputs=['d_onnx::Shape_345', '', '', 'd_input.27'],
                            name='SkipLayerNorm_1',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node(
                            'DecoderMaskedSelfAttention',
                            inputs=[
                                'd_onnx::Shape_345',
                                's_d_transformer.h.1.attn.c_attn.weight',
                                'd_transformer.h.1.attn.c_attn.bias',
                                'attention_mask',
                                'd_graph_input_cast_4',
                                '',
                                'past_sequence_length',
                                'beam_width',
                                'cache_indirection',
                            ],
                            outputs=['d_GptAttention_1_output', 'd_graph_output_cast_2'],
                            name='GptAttention_1',
                            domain='com.microsoft',
                            mask_filter_value=-3.4028234663852886e+38,
                            num_heads=8,
                            past_present_share_buffer=1,
                        ),
                        make_node('MatMul', inputs=['d_GptAttention_1_output', 'd_transformer.h.1.attn.c_proj.weight'], outputs=['d_GptAttention_1_matmul_output'], name='GptAttention_1_matmul'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['d_input.27', 'd_GptAttention_1_matmul_output', 'd_transformer.h.1.ln_2.weight', 'd_transformer.h.1.ln_2.bias', 'd_transformer.h.1.attn.c_proj.bias'],
                            outputs=['d_onnx::Shape_518', '', '', 'd_input.39'],
                            name='SkipLayerNorm_AddBias_1',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('Shape', inputs=['d_onnx::Shape_518'], outputs=['d_onnx::Gather_525'], name='Shape_442'),
                        make_node('Gather', inputs=['d_onnx::Gather_525', 'd_onnx::Gather_526'], outputs=['d_onnx::Unsqueeze_527'], name='Gather_444', axis=0),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_527'], outputs=['d_onnx::Concat_579'], name='Unsqueeze_489', axes=[0]),
                        make_node('Concat', inputs=['d_onnx::Concat_851', 'd_onnx::Concat_579'], outputs=['d_onnx::Reshape_531'], name='Concat_446', axis=0),
                        make_node('Reshape', inputs=['d_onnx::Shape_518', 'd_onnx::Reshape_531'], outputs=['d_onnx::MatMul_532'], name='Reshape_447'),
                        make_node('MatMul', inputs=['d_onnx::MatMul_532', 'd_onnx::MatMul_887'], outputs=['d_input.43'], name='MatMul_448'),
                        make_node('MatMul', inputs=['d_input.43', 'd_onnx::MatMul_550'], outputs=['d_onnx::Softmax_551'], name='MatMul_461'),
                        make_node(
                            'MoEBlock',
                            inputs=[
                                'd_onnx::Shape_518',
                                '',
                                's_d_transformer.h.1.mlp.moe_experts.weight1',
                                's_d_transformer.h.1.mlp.moe_experts.weight2',
                                's_d_transformer.h.1.mlp.moe_experts.bias1',
                                'd_transformer.h.1.mlp.moe_experts.bias2',
                                'd_onnx::Softmax_551',
                            ],
                            outputs=['d_onnx::Add_581'],
                            name='MoEBlock_0',
                            domain='com.microsoft',
                        ),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['d_input.39', 'd_onnx::Add_581', 'd_transformer.h.2.ln_1.weight', 'd_transformer.h.2.ln_1.bias'],
                            outputs=['d_onnx::Shape_593', '', '', 'd_input.51'],
                            name='SkipLayerNorm_3',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node(
                            'DecoderMaskedSelfAttention',
                            inputs=[
                                'd_onnx::Shape_593',
                                's_d_transformer.h.2.attn.c_attn.weight',
                                'd_transformer.h.2.attn.c_attn.bias',
                                'attention_mask',
                                'd_graph_input_cast_5',
                                '',
                                'past_sequence_length',
                                'beam_width',
                                'cache_indirection',
                            ],
                            outputs=['d_GptAttention_2_output', 'd_graph_output_cast_3'],
                            name='GptAttention_2',
                            domain='com.microsoft',
                            mask_filter_value=-3.4028234663852886e+38,
                            num_heads=8,
                            past_present_share_buffer=1,
                        ),
                        make_node('MatMul', inputs=['d_GptAttention_2_output', 'd_transformer.h.2.attn.c_proj.weight'], outputs=['d_GptAttention_2_matmul_output'], name='GptAttention_2_matmul'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['d_input.51', 'd_GptAttention_2_matmul_output', 'd_transformer.h.2.ln_2.weight', 'd_transformer.h.2.ln_2.bias', 'd_transformer.h.2.attn.c_proj.bias'],
                            outputs=['d_FullyConnect_MatMul_1_input', '', '', 'd_input.63'],
                            name='SkipLayerNorm_AddBias_2',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('MatMul', inputs=['d_FullyConnect_MatMul_1_input', 's_d_transformer.h.2.mlp.c_fc.weight'], outputs=['d_FullyConnect_MatMul_1_output'], name='FullyConnect_MatMul_1'),
                        make_node('BiasGelu', inputs=['d_FullyConnect_MatMul_1_output', 's_d_transformer.h.2.mlp.c_fc.bias'], outputs=['d_onnx::Shape_798'], name='Gelu_AddBias_1', domain='com.microsoft'),
                        make_node('Shape', inputs=['d_onnx::Shape_798'], outputs=['d_onnx::Gather_802'], name='Shape_677'),
                        make_node('Gather', inputs=['d_onnx::Gather_802', 'd_onnx::Gather_803'], outputs=['d_onnx::Unsqueeze_804'], name='Gather_679', axis=0),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_804'], outputs=['d_onnx::Concat_819'], name='Unsqueeze_691', axes=[0]),
                        make_node('Gather', inputs=['d_onnx::Gather_802', 'd_onnx::Gather_800'], outputs=['d_onnx::Unsqueeze_801'], name='Gather_676', axis=0),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_801'], outputs=['d_onnx::Concat_818'], name='Unsqueeze_690', axes=[0]),
                        make_node('Concat', inputs=['d_onnx::Concat_818', 'd_onnx::Concat_819', 'd_onnx::Concat_865'], outputs=['d_onnx::Reshape_821'], name='Concat_692', axis=0),
                        make_node('Slice', inputs=['d_onnx::Gather_802', 'd_onnx::Concat_851', 'd_onnx::Slice_319', 'd_onnx::Slice_806'], outputs=['d_onnx::Squeeze_809'], name='Slice_684'),
                        make_node('Squeeze', inputs=['d_onnx::Squeeze_809'], outputs=['d_onnx::Unsqueeze_810'], name='Squeeze_685', axes=[0]),
                        make_node('Unsqueeze', inputs=['d_onnx::Unsqueeze_810'], outputs=['d_onnx::Concat_813'], name='Unsqueeze_686', axes=[0]),
                        make_node('Concat', inputs=['d_onnx::Concat_851', 'd_onnx::Concat_813'], outputs=['d_onnx::Reshape_814'], name='Concat_687', axis=0),
                        make_node('Reshape', inputs=['d_onnx::Shape_798', 'd_onnx::Reshape_814'], outputs=['d_onnx::Gemm_815'], name='Reshape_688'),
                        make_node(
                            'Gemm',
                            inputs=['d_onnx::Gemm_815', 's_d_transformer.h.2.mlp.c_proj.weight', 'd_transformer.h.2.mlp.c_proj.bias'],
                            outputs=['d_onnx::Reshape_816'],
                            name='Gemm_689',
                            transB=0,
                            transA=0,
                            alpha=1.0,
                            beta=1.0,
                        ),
                        make_node('Reshape', inputs=['d_onnx::Reshape_816', 'd_onnx::Reshape_821'], outputs=['d_input.67'], name='Reshape_693'),
                        make_node(
                            'SkipLayerNormalization',
                            inputs=['d_input.63', 'd_input.67', 'd_transformer.ln_f.weight', 'd_transformer.ln_f.bias'],
                            outputs=['d_onnx::Reshape_834'],
                            name='SkipLayerNorm_5',
                            domain='com.microsoft',
                            epsilon=9.999999747378752e-06,
                        ),
                        make_node('MatMul', inputs=['d_onnx::Reshape_834', 's_d_onnx::MatMul_908'], outputs=['d_graph_output_cast_0'], name='MatMul_711'),
                        make_node('Cast', inputs=['d_graph_output_cast_0'], outputs=['logits'], name='graph_output_cast0', to=TensorProto.FLOAT),
                        make_node('Cast', inputs=['d_graph_output_cast_1'], outputs=['present_0'], name='graph_output_cast1', to=TensorProto.FLOAT),
                        make_node('Cast', inputs=['d_graph_output_cast_2'], outputs=['present_1'], name='graph_output_cast2', to=TensorProto.FLOAT),
                        make_node('Cast', inputs=['d_graph_output_cast_3'], outputs=['present_2'], name='graph_output_cast3', to=TensorProto.FLOAT),
                    ],
                ),
            ),
        ],
    ),
)

if __name__ == '__main__' and len(sys.argv) == 2:
    _, out_path = sys.argv
    onnx.save(model, out_path)
